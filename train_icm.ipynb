{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19Of4GcAQzeL",
    "outputId": "650ee55f-9d53-4328-b7d6-fe07fe986684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJjqjMZfhsw6",
    "outputId": "2f4ebe3d-b1f5-406f-811c-fb1c24a053c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'In-Context-Matting'...\n",
      "remote: Enumerating objects: 74, done.\u001b[K\n",
      "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
      "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
      "remote: Total 74 (delta 25), reused 60 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (74/74), 56.34 KiB | 861.00 KiB/s, done.\n",
      "Resolving deltas: 100% (25/25), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the GitHub repository\n",
    "# !git clone https://github.com/tiny-smart/in-context-matting.git\n",
    "!git clone https://github.com/MatteoMaske/In-Context-Matting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBvcI4UNTCpq"
   },
   "outputs": [],
   "source": [
    "%cp -r drive/MyDrive/ACV/ICM57 In-Context-Matting/datasets/\n",
    "%cp drive/MyDrive/ACV/IN-CONTEXT-MATTING/models/12-0.00800-mat.pth In-Context-Matting/\n",
    "%mv In-Context-Matting/12-0.00800-mat.pth In-Context-Matting/model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_FlcuW7UWyO",
    "outputId": "03ba1a6d-094f-4620-81f0-f4bc66567ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/In-Context-Matting\n"
     ]
    }
   ],
   "source": [
    "%cd In-Context-Matting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "cS5_WOoJoNBI",
    "outputId": "c63097fc-6204-49a5-ea5b-5b286c00f6ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers==0.18.1 (from -r colab_requirements.txt (line 1))\n",
      "  Downloading diffusers-0.18.1.tar.gz (895 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/895.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m890.9/895.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.8/895.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting omegaconf==2.3.0 (from -r colab_requirements.txt (line 2))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-lightning==1.4.2 (from -r colab_requirements.txt (line 3))\n",
      "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jax==0.4.23 (from -r colab_requirements.txt (line 4))\n",
      "  Downloading jax-0.4.23-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jaxlib==0.4.23 (from -r colab_requirements.txt (line 5))\n",
      "  Downloading jaxlib-0.4.23-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting xformers (from -r colab_requirements.txt (line 6))\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting torchmetrics==0.6.0 (from -r colab_requirements.txt (line 7))\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting huggingface_hub==0.14.1 (from -r colab_requirements.txt (line 8))\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting matplotlib==3.7.1 (from -r colab_requirements.txt (line 9))\n",
      "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting numpy==1.26 (from -r colab_requirements.txt (line 10))\n",
      "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.19.0 (from -r colab_requirements.txt (line 11))\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers==4.29.2 (from -r colab_requirements.txt (line 12))\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r colab_requirements.txt (line 13)) (4.10.0.84)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r colab_requirements.txt (line 14)) (2.5.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r colab_requirements.txt (line 15)) (0.20.0+cu121)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r colab_requirements.txt (line 16)) (0.24.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.1->-r colab_requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.1->-r colab_requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.1->-r colab_requirements.txt (line 1)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.1->-r colab_requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.1->-r colab_requirements.txt (line 1)) (11.0.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r colab_requirements.txt (line 2))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.3.0->-r colab_requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (4.66.6)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (2024.10.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (2.17.0)\n",
      "Collecting pyDeprecate==0.3.1 (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3))\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->-r colab_requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->-r colab_requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->-r colab_requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0->-r colab_requirements.txt (line 11)) (5.9.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->-r colab_requirements.txt (line 12))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch (from -r colab_requirements.txt (line 14))\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r colab_requirements.txt (line 14)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r colab_requirements.txt (line 14)) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->-r colab_requirements.txt (line 14))\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r colab_requirements.txt (line 14)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r colab_requirements.txt (line 14)) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from -r colab_requirements.txt (line 15))\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r colab_requirements.txt (line 16)) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r colab_requirements.txt (line 16)) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r colab_requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (3.10.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.1->-r colab_requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.67.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (4.25.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.18.1->-r colab_requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r colab_requirements.txt (line 14)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.1->-r colab_requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.1->-r colab_requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.1->-r colab_requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.1->-r colab_requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r colab_requirements.txt (line 3)) (0.2.0)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m916.6/916.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.23-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.23-cp310-cp310-manylinux2014_x86_64.whl (77.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.2/77.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.4/329.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: diffusers, antlr4-python3-runtime\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for diffusers: filename=diffusers-0.18.1-py3-none-any.whl size=1247763 sha256=f7cf8ffbfffac1772d09714b64967aaade2723ab7d39ff4b732ba1b7e7fab7c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/24/a6/0f/76cc29c67a153b1a711662ce4181c8463815f1186336ba07ec\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=1246766ffc07b2f3d5bccd61dc4cf6e17ecf2072dac3d488c8e8901b45d55091\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built diffusers antlr4-python3-runtime\n",
      "Installing collected packages: tokenizers, antlr4-python3-runtime, triton, pyDeprecate, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, transformers, nvidia-cusolver-cu12, matplotlib, jaxlib, jax, diffusers, torch, xformers, torchvision, torchmetrics, accelerate, pytorch-lightning\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.26.2\n",
      "    Uninstalling huggingface-hub-0.26.2:\n",
      "      Successfully uninstalled huggingface-hub-0.26.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.2\n",
      "    Uninstalling transformers-4.46.2:\n",
      "      Successfully uninstalled transformers-4.46.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.0\n",
      "    Uninstalling matplotlib-3.8.0:\n",
      "      Successfully uninstalled matplotlib-3.8.0\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.33\n",
      "    Uninstalling jaxlib-0.4.33:\n",
      "      Successfully uninstalled jaxlib-0.4.33\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.33\n",
      "    Uninstalling jax-0.4.33:\n",
      "      Successfully uninstalled jax-0.4.33\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.31.0\n",
      "    Uninstalling diffusers-0.31.0:\n",
      "      Successfully uninstalled diffusers-0.31.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0+cu121\n",
      "    Uninstalling torch-2.5.0+cu121:\n",
      "      Successfully uninstalled torch-2.5.0+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.0+cu121\n",
      "    Uninstalling torchvision-0.20.0+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.0+cu121\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.1.1\n",
      "    Uninstalling accelerate-1.1.1:\n",
      "      Successfully uninstalled accelerate-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
      "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.23 which is incompatible.\n",
      "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
      "optax 0.2.3 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
      "optax 0.2.3 requires jaxlib>=0.4.27, but you have jaxlib 0.4.23 which is incompatible.\n",
      "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.23 which is incompatible.\n",
      "peft 0.13.2 requires accelerate>=0.21.0, but you have accelerate 0.19.0 which is incompatible.\n",
      "peft 0.13.2 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
      "sentence-transformers 3.2.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.29.2 which is incompatible.\n",
      "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.19.0 antlr4-python3-runtime-4.9.3 diffusers-0.18.1 huggingface_hub-0.14.1 jax-0.4.23 jaxlib-0.4.23 matplotlib-3.7.1 numpy-1.26.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.2 tokenizers-0.13.3 torch-2.5.1 torchmetrics-0.6.0 torchvision-0.20.1 transformers-4.29.2 triton-3.1.0 xformers-0.0.28.post3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "570f84711d7a47f1b2d83f2edce3ed3e",
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits",
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -r colab_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b7UTwChS-AA"
   },
   "source": [
    "# Eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwea1beYSnNO"
   },
   "source": [
    "PROVARE AD ABBASSARE IL BATCH, dopo un po esplode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od-ZW3nSb8uT"
   },
   "source": [
    "Change the following file:\n",
    "In-Context-Matting/config/eval.yaml\n",
    "line 32 load_local to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTV75QWUmClS",
    "outputId": "edf2d181-b6bd-4933-9405-4a015d96a5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-15 14:24:48.733360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 14:24:48.753545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 14:24:48.759670: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 14:24:51.485764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Global seed set to 42\n",
      "Loading model from model.pth\n",
      "/content/In-Context-Matting/eval.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
      "Downloading unet/config.json: 100% 939/939 [00:00<00:00, 4.93MB/s]\n",
      "Downloading (…)on_pytorch_model.bin: 100% 3.46G/3.46G [00:29<00:00, 116MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Downloading model_index.json: 100% 537/537 [00:00<00:00, 2.91MB/s]\n",
      "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n",
      "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 1.98MB/s]\n",
      "Fetching 11 files:   9% 1/11 [00:00<00:01,  5.31it/s]\n",
      "Downloading (…)_encoder/config.json: 100% 633/633 [00:00<00:00, 4.99MB/s]\n",
      "\n",
      "Downloading tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)okenizer_config.json: 100% 824/824 [00:00<00:00, 5.21MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)cheduler_config.json: 100% 345/345 [00:00<00:00, 2.43MB/s]\n",
      "\n",
      "\n",
      "Downloading tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   0% 0.00/1.36G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading vae/config.json: 100% 611/611 [00:00<00:00, 2.75MB/s]\n",
      "\n",
      "Downloading tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 2.64MB/s]\n",
      "\n",
      "\n",
      "Downloading tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.22MB/s]\n",
      "\n",
      "Downloading (…)on_pytorch_model.bin:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   1% 10.5M/1.36G [00:00<00:27, 49.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.29MB/s]\n",
      "\n",
      "Downloading (…)on_pytorch_model.bin:   6% 21.0M/335M [00:00<00:02, 154MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   2% 21.0M/1.36G [00:00<00:22, 60.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  16% 52.4M/335M [00:00<00:01, 202MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   2% 31.5M/1.36G [00:00<00:18, 71.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  22% 73.4M/335M [00:00<00:01, 170MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   4% 52.4M/1.36G [00:00<00:13, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  28% 94.4M/335M [00:00<00:01, 174MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   5% 73.4M/1.36G [00:00<00:11, 110MB/s] \u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  34% 115M/335M [00:00<00:01, 177MB/s] \u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  41% 136M/335M [00:00<00:01, 182MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   7% 94.4M/1.36G [00:00<00:10, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   8% 115M/1.36G [00:01<00:08, 139MB/s] \u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  47% 157M/335M [00:00<00:00, 179MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  10% 136M/1.36G [00:01<00:08, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  53% 178M/335M [00:01<00:00, 162MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  12% 168M/1.36G [00:01<00:07, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  63% 210M/335M [00:01<00:00, 178MB/s]\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  69% 231M/335M [00:01<00:00, 166MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  14% 189M/1.36G [00:01<00:08, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  15% 210M/1.36G [00:01<00:08, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  75% 252M/335M [00:01<00:00, 137MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  17% 231M/1.36G [00:01<00:09, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  81% 273M/335M [00:01<00:00, 116MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  18% 252M/1.36G [00:02<00:09, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  88% 294M/335M [00:01<00:00, 116MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  20% 273M/1.36G [00:02<00:10, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin:  94% 315M/335M [00:02<00:00, 108MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  22% 294M/1.36G [00:02<00:09, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)on_pytorch_model.bin: 100% 335M/335M [00:02<00:00, 139MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  23% 315M/1.36G [00:02<00:09, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  25% 336M/1.36G [00:02<00:08, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  26% 357M/1.36G [00:02<00:07, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  28% 377M/1.36G [00:03<00:06, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  29% 398M/1.36G [00:03<00:06, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  32% 430M/1.36G [00:03<00:05, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  33% 451M/1.36G [00:03<00:05, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  35% 472M/1.36G [00:03<00:05, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  36% 493M/1.36G [00:03<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  38% 514M/1.36G [00:03<00:04, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  39% 535M/1.36G [00:03<00:04, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  41% 556M/1.36G [00:04<00:04, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  42% 577M/1.36G [00:04<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  44% 598M/1.36G [00:04<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  45% 619M/1.36G [00:04<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  47% 640M/1.36G [00:04<00:04, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  49% 661M/1.36G [00:04<00:04, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  50% 682M/1.36G [00:04<00:04, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  52% 703M/1.36G [00:04<00:04, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  53% 724M/1.36G [00:05<00:04, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  55% 744M/1.36G [00:05<00:03, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  56% 765M/1.36G [00:05<00:03, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  58% 786M/1.36G [00:05<00:03, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  59% 807M/1.36G [00:05<00:03, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  61% 828M/1.36G [00:05<00:02, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  63% 860M/1.36G [00:05<00:02, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  65% 881M/1.36G [00:06<00:02, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  66% 902M/1.36G [00:06<00:03, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  68% 923M/1.36G [00:06<00:02, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  69% 944M/1.36G [00:07<00:11, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  71% 965M/1.36G [00:09<00:15, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  73% 996M/1.36G [00:09<00:09, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  75% 1.02G/1.36G [00:09<00:06, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  76% 1.04G/1.36G [00:09<00:05, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  78% 1.06G/1.36G [00:09<00:03, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  79% 1.08G/1.36G [00:09<00:03, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  81% 1.10G/1.36G [00:10<00:02, 99.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  82% 1.12G/1.36G [00:10<00:02, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  84% 1.14G/1.36G [00:10<00:02, 77.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  85% 1.16G/1.36G [00:11<00:02, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  86% 1.17G/1.36G [00:11<00:02, 73.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  88% 1.20G/1.36G [00:11<00:01, 83.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  89% 1.21G/1.36G [00:13<00:06, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  89% 1.22G/1.36G [00:15<00:12, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  92% 1.25G/1.36G [00:15<00:05, 21.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  93% 1.27G/1.36G [00:15<00:03, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  95% 1.29G/1.36G [00:16<00:01, 40.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  96% 1.31G/1.36G [00:16<00:00, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin:  98% 1.33G/1.36G [00:16<00:00, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading pytorch_model.bin: 100% 1.36G/1.36G [00:16<00:00, 82.8MB/s]\n",
      "Fetching 11 files: 100% 11/11 [00:16<00:00,  1.52s/it]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "missing keys:\n",
      "['feature_extractor.prompt_embeds', 'feature_extractor.dift_sd.vae.encoder.conv_in.weight', 'feature_extractor.dift_sd.vae.encoder.conv_in.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.0.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.resnets.1.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.0.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.resnets.1.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.1.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.resnets.1.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.2.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.0.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.down_blocks.3.resnets.1.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.group_norm.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.group_norm.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_q.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_q.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_k.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_k.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_v.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_v.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_out.0.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.attentions.0.to_out.0.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.0.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.norm1.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.norm1.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.conv1.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.conv1.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.norm2.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.norm2.bias', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.conv2.weight', 'feature_extractor.dift_sd.vae.encoder.mid_block.resnets.1.conv2.bias', 'feature_extractor.dift_sd.vae.encoder.conv_norm_out.weight', 'feature_extractor.dift_sd.vae.encoder.conv_norm_out.bias', 'feature_extractor.dift_sd.vae.encoder.conv_out.weight', 'feature_extractor.dift_sd.vae.encoder.conv_out.bias', 'feature_extractor.dift_sd.vae.quant_conv.weight', 'feature_extractor.dift_sd.vae.quant_conv.bias', 'feature_extractor.dift_sd.vae.post_quant_conv.weight', 'feature_extractor.dift_sd.vae.post_quant_conv.bias', 'feature_extractor.dift_sd.unet.conv_in.weight', 'feature_extractor.dift_sd.unet.conv_in.bias', 'feature_extractor.dift_sd.unet.time_embedding.linear_1.weight', 'feature_extractor.dift_sd.unet.time_embedding.linear_1.bias', 'feature_extractor.dift_sd.unet.time_embedding.linear_2.weight', 'feature_extractor.dift_sd.unet.time_embedding.linear_2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.0.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.down_blocks.0.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.1.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.down_blocks.1.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.2.downsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.down_blocks.2.downsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.down_blocks.3.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.1.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.resnets.2.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.0.upsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.up_blocks.0.upsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.attentions.2.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.1.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.resnets.2.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.1.upsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.up_blocks.1.upsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.attentions.2.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.1.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.resnets.2.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.2.upsamplers.0.conv.weight', 'feature_extractor.dift_sd.unet.up_blocks.2.upsamplers.0.conv.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.1.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.norm.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.norm.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.proj_in.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.proj_in.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.proj_out.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.attentions.2.proj_out.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.0.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.1.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.norm1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.norm1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv1.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv1.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.norm2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.norm2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv2.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv2.bias', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv_shortcut.weight', 'feature_extractor.dift_sd.unet.up_blocks.3.resnets.2.conv_shortcut.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.norm.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.norm.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.proj_in.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.proj_in.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm1.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm1.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm2.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm2.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm3.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.norm3.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.proj_out.weight', 'feature_extractor.dift_sd.unet.mid_block.attentions.0.proj_out.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.norm1.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.norm1.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.conv1.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.conv1.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.norm2.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.norm2.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.conv2.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.0.conv2.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.norm1.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.norm1.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.conv1.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.conv1.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.time_emb_proj.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.time_emb_proj.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.norm2.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.norm2.bias', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.conv2.weight', 'feature_extractor.dift_sd.unet.mid_block.resnets.1.conv2.bias', 'feature_extractor.dift_sd.unet.conv_norm_out.weight', 'feature_extractor.dift_sd.unet.conv_norm_out.bias', 'feature_extractor.dift_sd.unet.conv_out.weight', 'feature_extractor.dift_sd.unet.conv_out.bias']\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All DDP processes registered. Starting ddp with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: logs/eval\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/data_loading.py:372: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "Validating:   0% 0/232 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `text_encoder` directly via 'OneStepSDPipeline' object attribute is deprecated. Please access 'text_encoder' over 'OneStepSDPipeline's config object instead, e.g. 'scheduler.config.text_encoder'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `tokenizer` directly via 'OneStepSDPipeline' object attribute is deprecated. Please access 'tokenizer' over 'OneStepSDPipeline's config object instead, e.g. 'scheduler.config.tokenizer'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "Validating:  43% 100/232 [19:14<25:28, 11.58s/it][rank0]: \u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/\u001b[0m\u001b[1;33meval.py\u001b[0m:\u001b[94m132\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   \u001b[0mtrainer = Trainer.from_argparse_args(trainer_opt)                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# init logger\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   \u001b[0mmodel.val_save_path = args.save_path                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m132 \u001b[2m│   \u001b[0mtrainer.validate(model, data.val_dataloader())                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m628\u001b[0m in \u001b[92mvalidate\u001b[0m     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 625 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.validated_ckpt_path = \u001b[96mself\u001b[0m.__load_ckpt_weights(ckpt_path)                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 626 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 627 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# run validate\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 628 \u001b[2m│   │   \u001b[0mresults = \u001b[96mself\u001b[0m._run(model)                                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 629 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.validating = \u001b[94mFalse\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m918\u001b[0m in \u001b[92m_run\u001b[0m         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 915 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.checkpoint_connector.restore_training_state()                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 916 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 917 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 918 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._dispatch()                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 919 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 920 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 921 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._post_dispatch()                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m982\u001b[0m in \u001b[92m_dispatch\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 980 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_dispatch\u001b[0m(\u001b[96mself\u001b[0m):                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 981 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.evaluating:                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 982 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.start_evaluating(\u001b[96mself\u001b[0m)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 983 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.predicting:                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 984 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.start_predicting(\u001b[96mself\u001b[0m)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 985 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m95\u001b[0m in      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92mstart_evaluating\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training_type_plugin.start_training(trainer)                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstart_evaluating\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 95 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training_type_plugin.start_evaluating(trainer)                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstart_predicting\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training_type_plugin.start_predicting(trainer)                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/\u001b[0m\u001b[1;33mtraining_type_pl\u001b[0m \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[1;33mugin.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mstart_evaluating\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstart_evaluating\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# double dispatch to initiate the test loop\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._results = trainer.run_stage()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mstart_predicting\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# double dispatch to initiate the predicting loop\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m993\u001b[0m in \u001b[92mrun_stage\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 990 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.__setup_profiler()                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 991 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 992 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.evaluating:                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 993 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._run_evaluate()                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 994 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.predicting:                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 995 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._run_predict()                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 996 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._run_train()                                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1079\u001b[0m in             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92m_run_evaluate\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._evaluation_loop.trainer = \u001b[96mself\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.profiler.profile(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mrun_\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.state.stage\u001b[33m}\u001b[0m\u001b[33m_evaluation\u001b[0m\u001b[33m\"\u001b[0m), torch.no_grad(  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1079 \u001b[2m│   │   │   \u001b[0meval_loop_results = \u001b[96mself\u001b[0m._evaluation_loop.run()                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1080 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1081 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove the tensors from the eval results\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1082 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m i, result \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(eval_loop_results):                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m111\u001b[0m in \u001b[92mrun\u001b[0m               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_start(*args, **kwargs)                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m111 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_end()                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.iteration_count += \u001b[94m1\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.restarting = \u001b[94mFalse\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/\u001b[0m\u001b[1;33mevaluation_loop.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[94m0\u001b[0m in \u001b[92madvance\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   \u001b[0mdataloader_iter = \u001b[96menumerate\u001b[0m(dataloader)                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0mdl_max_batches = \u001b[96mself\u001b[0m._max_batches[\u001b[96mself\u001b[0m.current_dataloader_idx]                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m110 \u001b[2m│   │   \u001b[0mdl_outputs = \u001b[96mself\u001b[0m.epoch_loop.run(                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0mdataloader_iter, \u001b[96mself\u001b[0m.current_dataloader_idx, dl_max_batches, \u001b[96mself\u001b[0m.num_datal   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m111\u001b[0m in \u001b[92mrun\u001b[0m               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_start(*args, **kwargs)                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m111 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_end()                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.iteration_count += \u001b[94m1\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.restarting = \u001b[94mFalse\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/\u001b[0m\u001b[1;33mevaluation_epoch_loop.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[94m10\u001b[0m in \u001b[92madvance\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# lightning module methods\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.trainer.profiler.profile(\u001b[33m\"\u001b[0m\u001b[33mevaluation_step_and_end\u001b[0m\u001b[33m\"\u001b[0m):                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m110 \u001b[2m│   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.evaluation_step(batch, batch_idx, dataloader_idx)                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.evaluation_step_end(output)                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.batch_progress.increment_processed()                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/\u001b[0m\u001b[1;33mevaluation_epoch_loop.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[94m54\u001b[0m in \u001b[92mevaluation_step\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.lightning_module._current_fx_name = \u001b[33m\"\u001b[0m\u001b[33mvalidation_step\u001b[0m\u001b[33m\"\u001b[0m             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.trainer.profiler.profile(\u001b[33m\"\u001b[0m\u001b[33mvalidation_step\u001b[0m\u001b[33m\"\u001b[0m):                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m154 \u001b[2m│   │   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.trainer.accelerator.validation_step(step_kwargs)             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m output                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m211\u001b[0m in     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92mvalidation_step\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2;33m│   │   │   │     \u001b[0m\u001b[33m(only if multiple val dataloaders used)\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.precision_plugin.val_step_context(), \u001b[96mself\u001b[0m.training_type_plugin.val_ste   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m211 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.training_type_plugin.validation_step(*step_kwargs.values())        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtest_step\u001b[0m(\u001b[96mself\u001b[0m, step_kwargs: Dict[\u001b[96mstr\u001b[0m, Union[Any, \u001b[96mint\u001b[0m]]) -> Optional[STEP_OUTPUT   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"The actual test step.\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/\u001b[0m\u001b[1;33mddp.py\u001b[0m:\u001b[94m386\u001b[0m in    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92mvalidation_step\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m383 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.model(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m384 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m385 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mvalidation_step\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m386 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.model(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m387 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m388 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtest_step\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m389 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.model(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/\u001b[0m\u001b[1;33mdistributed.py\u001b[0m:\u001b[94m1643\u001b[0m in \u001b[92mforward\u001b[0m         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1640 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = (                                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1641 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.module.forward(*inputs, **kwargs)                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._delay_all_reduce_all_params                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1643 \u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m \u001b[96mself\u001b[0m._run_ddp_forward(*inputs, **kwargs)                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1645 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._post_forward(output)                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/\u001b[0m\u001b[1;33mdistributed.py\u001b[0m:\u001b[94m1459\u001b[0m in                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92m_run_ddp_forward\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1456 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.module(*inputs, **kwargs)  \u001b[2m# type: ignore[index]\u001b[0m                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1457 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1458 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._inside_ddp_forward():                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1459 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.module(*inputs, **kwargs)  \u001b[2m# type: ignore[index]\u001b[0m              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1460 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1461 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_clear_grad_buffer\u001b[0m(\u001b[96mself\u001b[0m):                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Making param.grad points to the grad buffers before backward is based on the\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m93\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 90 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m trainer \u001b[95mand\u001b[0m trainer.testing:                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.module.test_step(*inputs, **kwargs)                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m trainer \u001b[95mand\u001b[0m (trainer.sanity_checking \u001b[95mor\u001b[0m trainer.validating):                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 93 \u001b[2m│   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.module.validation_step(*inputs, **kwargs)                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m trainer \u001b[95mand\u001b[0m trainer.predicting:                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = \u001b[96mself\u001b[0m.module.predict_step(*inputs, **kwargs)                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/\u001b[0m\u001b[1;33min_context_matting.py\u001b[0m:\u001b[94m73\u001b[0m in \u001b[92mvalidation_step\u001b[0m               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss                                                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mvalidation_step\u001b[0m(\u001b[96mself\u001b[0m, batch, batch_idx):                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 73 \u001b[2m│   │   \u001b[0mloss_dict, loss, preds, cross_map, self_map = \u001b[96mself\u001b[0m.__shared_step(batch)            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.__log_loss(loss_dict, loss, \u001b[33m\"\u001b[0m\u001b[33mval\u001b[0m\u001b[33m\"\u001b[0m)                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0mbatch[\u001b[33m'\u001b[0m\u001b[33mcross_map\u001b[0m\u001b[33m'\u001b[0m] = cross_map                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/\u001b[0m\u001b[1;33min_context_matting.py\u001b[0m:\u001b[94m84\u001b[0m in \u001b[92m__shared_step\u001b[0m                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   │   \u001b[0mreference_images, guidance_on_reference_image, source_images, labels, trimaps =    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mreference_image\u001b[0m\u001b[33m\"\u001b[0m], batch[\u001b[33m\"\u001b[0m\u001b[33mguidance_on_reference_image\u001b[0m\u001b[33m\"\u001b[0m], batch[\u001b[33m\"\u001b[0m\u001b[33msource_imag\u001b[0m   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 84 \u001b[2m│   │   \u001b[0moutputs, cross_map, self_map = \u001b[96mself\u001b[0m(reference_images,                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   │   │   │   │      \u001b[0mguidance_on_reference_image, source_images)                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   │   \u001b[0msample_map = torch.zeros_like(trimaps)                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/\u001b[0m\u001b[1;33min_context_matting.py\u001b[0m:\u001b[94m42\u001b[0m in \u001b[92mforward\u001b[0m                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, reference_images, guidance_on_reference_image, source_images):       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   \u001b[0mfeature_of_reference_image = \u001b[96mself\u001b[0m.feature_extractor.get_reference_feature(         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   │   \u001b[0mreference_images)                                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mfeature_of_source_image = \u001b[96mself\u001b[0m.feature_extractor.get_source_feature(               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/feature_extractor/\u001b[0m\u001b[1;33mdift_sd.py\u001b[0m:\u001b[94m533\u001b[0m in \u001b[92mget_reference_feature\u001b[0m \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m530 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_reference_feature\u001b[0m(\u001b[96mself\u001b[0m, images):                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m531 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.controller.reset()                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m532 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_size = images.shape[\u001b[94m0\u001b[0m]                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m533 \u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.dift_sd.forward_feature_extractor(                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.prompt_embeds, images, t=\u001b[96mself\u001b[0m.time_steps[\u001b[94m0\u001b[0m], ensemble_size=\u001b[96mself\u001b[0m.ensembl   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m535 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m536 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.ensemble_feature(                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m116\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m116 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/feature_extractor/\u001b[0m\u001b[1;33mdift_sd.py\u001b[0m:\u001b[94m472\u001b[0m in                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[92mforward_feature_extractor\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m469 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m470 \u001b[0m\u001b[2m│   │   \u001b[0mprompt_embeds = uc.repeat(                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m471 \u001b[0m\u001b[2m│   │   │   \u001b[0mimg_tensor.shape[\u001b[94m0\u001b[0m], \u001b[94m1\u001b[0m, \u001b[94m1\u001b[0m).to(img_tensor.device)                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m472 \u001b[2m│   │   \u001b[0munet_ft_all = \u001b[96mself\u001b[0m.pipe(                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m473 \u001b[0m\u001b[2m│   │   │   \u001b[0mimg_tensor=img_tensor,                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m474 \u001b[0m\u001b[2m│   │   │   \u001b[0mt=t,                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m475 \u001b[0m\u001b[2m│   │   │   \u001b[0mup_ft_indices=up_ft_index,                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m116\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m116 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/In-Context-Matting/icm/models/feature_extractor/\u001b[0m\u001b[1;33mdift_sd.py\u001b[0m:\u001b[94m355\u001b[0m in \u001b[92m__call__\u001b[0m              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   \u001b[0m):                                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   \u001b[0mdevice = \u001b[96mself\u001b[0m._execution_device                                                    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2m│   │   \u001b[0mlatents = (                                                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m355 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.vae.encode(img_tensor).latent_dist.sample()                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   │   \u001b[0m* \u001b[96mself\u001b[0m.vae.config.scaling_factor                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   │   \u001b[0mt = torch.tensor(t, dtype=torch.long, device=device)                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/utils/\u001b[0m\u001b[1;33maccelerate_utils.py\u001b[0m:\u001b[94m46\u001b[0m in \u001b[92mwrapper\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m_hf_hook\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m._hf_hook, \u001b[33m\"\u001b[0m\u001b[33mpre_forward\u001b[0m\u001b[33m\"\u001b[0m):             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._hf_hook.pre_forward(\u001b[96mself\u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m46 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m method(\u001b[96mself\u001b[0m, *args, **kwargs)                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mautoencoder_kl.py\u001b[0m:\u001b[94m236\u001b[0m in \u001b[92mencode\u001b[0m         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoded_slices = [\u001b[96mself\u001b[0m.encoder(x_slice) \u001b[94mfor\u001b[0m x_slice \u001b[95min\u001b[0m x.split(\u001b[94m1\u001b[0m)]             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   │   \u001b[0mh = torch.cat(encoded_slices)                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m236 \u001b[2m│   │   │   \u001b[0mh = \u001b[96mself\u001b[0m.encoder(x)                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   │   \u001b[0mmoments = \u001b[96mself\u001b[0m.quant_conv(h)                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2m│   │   \u001b[0mposterior = DiagonalGaussianDistribution(moments)                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mvae.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# down\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m down_block \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.down_blocks:                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   │   \u001b[0msample = down_block(sample)                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# middle\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   │   \u001b[0msample = \u001b[96mself\u001b[0m.mid_block(sample)                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_blocks.py\u001b[0m:\u001b[94m1150\u001b[0m in \u001b[92mforward\u001b[0m       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, hidden_states):                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1149 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m resnet \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.resnets:                                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1150 \u001b[2m│   │   │   \u001b[0mhidden_states = resnet(hidden_states, temb=\u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1151 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.downsamplers \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1153 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m downsampler \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.downsamplers:                                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1736\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1735 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1736 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# torchrec tests the code consistency with the following code\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1739 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# fmt: off\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1747\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1746 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1747 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1750 \u001b[0m\u001b[2m│   │   \u001b[0mcalled_always_called_hooks = \u001b[96mset\u001b[0m()                                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mresnet.py\u001b[0m:\u001b[94m638\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m635 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.conv_shortcut \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m636 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_tensor = \u001b[96mself\u001b[0m.conv_shortcut(input_tensor)                                \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m637 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m638 \u001b[2m│   │   \u001b[0moutput_tensor = (input_tensor + hidden_states) / \u001b[96mself\u001b[0m.output_scale_factor          \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m639 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m output_tensor                                                               \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m641 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
      "[rank0]: \u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "[rank0]: \u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m1.12\u001b[0m GiB. GPU \u001b[1;36m0\u001b[0m has a total capacity of \n",
      "[rank0]: \u001b[1;36m14.75\u001b[0m GiB of which \u001b[1;36m1.03\u001b[0m GiB is free. Process \u001b[1;36m69120\u001b[0m has \u001b[1;36m13.72\u001b[0m GiB memory in use. Of the allocated \n",
      "[rank0]: memory \u001b[1;36m12.18\u001b[0m GiB is allocated by PyTorch, and \u001b[1;36m1.10\u001b[0m GiB is reserved by PyTorch but unallocated. If \n",
      "[rank0]: reserved but unallocated memory is large try setting \n",
      "[rank0]: \u001b[33mPYTORCH_CUDA_ALLOC_CONF\u001b[0m=\u001b[35mexpandable_segments\u001b[0m:\u001b[3;92mTrue\u001b[0m to avoid fragmentation.  See documentation for \n",
      "[rank0]: Memory Management  \u001b[1m(\u001b[0m\u001b[4;94mhttps://pytorch.org/docs/stable/notes/cuda.html#environment-variables\u001b[0m\u001b[4;94m)\u001b[0m\n",
      "[rank0]:[W1115 14:45:22.648950167 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --checkpoint model.pth --save_path results/ --config config/eval.yaml"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (InContextMattingTest)",
   "name": "incontextmattingtest"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
